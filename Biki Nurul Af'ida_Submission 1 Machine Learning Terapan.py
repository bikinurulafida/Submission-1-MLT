# -*- coding: utf-8 -*-
"""Biki Nurul Af'ida_Submission 1 Machine Learning Terapan

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18tqaGMcA45J1Na5o0GO8QrcppzVjLOAV

# Data Loading

Data yang digunakan adalah dataset Health and Lifestyle Data for Regression yang diambil dari Kaggle (https://www.kaggle.com/datasets/pratikyuvrajchougule/health-and-lifestyle-data-for-regression).
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline
import seaborn as sns
from sklearn.neighbors import KNeighborsRegressor
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

from google.colab import drive
drive.mount('/content/drive')
data = pd.read_csv('/content/drive/MyDrive/DBS/Data/health_data.csv')
data.head()

"""# Exploratory Data Analysis - Deskripsi Variabel

Deskripsi Fitur
Berdasarkan informasi dari Kaggle, fitur-fitur pada dataset adalah sebagai berikut:

- Age: Usia individu dalam tahun (fitur kontinu).
- BMI: Body Mass Index individu (fitur kontinu).
- Exercise_Frequency: Jumlah hari dalam seminggu individu berolahraga (fitur kategorikal dengan nilai 0-7).
- Diet_Quality: Indeks kualitas diet, semakin tinggi nilai menunjukkan pola makan yang lebih sehat (fitur kontinu, rentang 0-100).
- Sleep_Hours: Rata-rata jam tidur per malam (fitur kontinu).
- Smoking_Status: Status merokok (fitur biner, 0 = bukan perokok, 1 = perokok).
- Alcohol_Consumption: Rata-rata konsumsi alkohol dalam satuan unit per minggu (fitur kontinu).
- Health_Score: Skor kesehatan yang dihitung sebagai indikator status kesehatan keseluruhan (fitur kontinu, rentang 0-100).
"""

data.info()

data.describe()

data.shape

"""Dataset terdiri dari 1000 baris data dan 8 kolom.

## Mengecek Missing Value
"""

pd.DataFrame({'Nilai yang Kosong':data.isna().sum()})

"""Pada dataset tidak terdapat missing values.

## Mengecek Duplikasi Data
"""

duplicate_rows = data[data.duplicated()]
print(f"Jumlah baris duplikat: {len(duplicate_rows)}")
print(duplicate_rows.head())

"""Pada dataset tidak terdapat data duplikat.

## Mengecek Outliers
"""

numerical_features = ['Age', 'BMI', 'Exercise_Frequency', 'Diet_Quality', 'Sleep_Hours','Alcohol_Consumption', 'Health_Score']

for col in numerical_features:
    plt.figure(figsize=(8, 4))
    sns.boxplot(x=data[col])
    plt.title(f'Boxplot of {col}')
    plt.show()

# Fungsi deteksi outlier dengan metode IQR
def detect_outliers_iqr(data, col):
    Q1 = data[col].quantile(0.25)
    Q3 = data[col].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    outliers = data[(data[col] < lower_bound) | (data[col] > upper_bound)]
    return outliers

for col in numerical_features:
    outliers = detect_outliers_iqr(data, col)
    print(f"Kolom '{col}' memiliki {len(outliers)} outlier.")
    print("-" * 40)

"""Dari visualisasi boxplot tersebut dapat terlihat bahwa terdapat beberapa fitur yang memiliki outliers, yaitu Age (8 outliers), BMI (8 outliers), Alcohol Consumption (5 outliers), Diet Quality (3 outliers), Sleep Hours (6 outliers), dan Health Score (3 outliers).

## Menangani Outliers
"""

def handle_outliers_iqr(data, cols):
    data_handled = data.copy()
    for col in cols:
        Q1 = data[col].quantile(0.25)
        Q3 = data[col].quantile(0.75)

        # Ganti nilai yang lebih kecil dari Q1 dengan Q1
        data_handled.loc[data_handled[col] < Q1, col] = Q1

        # Ganti nilai yang lebih besar dari Q3 dengan Q3
        data_handled.loc[data_handled[col] > Q3, col] = Q3

    return data_handled

data_cleaned = handle_outliers_iqr(data, numerical_features)

# Cek ulang outlier setelah penanganan
for col in numerical_features:
    outliers = detect_outliers_iqr(data_cleaned, col)
    print(f"Setelah penanganan, kolom '{col}' memiliki {len(outliers)} outlier.")
    print("-" * 40)

"""Setelah dilakukan penanganan outlier menggunakan winsorizing (nilai yang berada di bawah Q1 akan diganti dengan nilai Q1 dan nilai yang berada di atas Q3 akan diganti dengan nilai Q3), fitur-fitur pada dataset sudah tidak terdapat outlier.

## Univariate Analysis

### Categorical Feature
"""

numerical_features = ['Age', 'BMI', 'Exercise_Frequency', 'Diet_Quality', 'Sleep_Hours','Alcohol_Consumption', 'Health_Score']
categorical_features = ['Smoking_Status']

import pandas as pd
import matplotlib.pyplot as plt

plt.figure(figsize=(7,7))
feature = categorical_features[0]
count = data[feature].value_counts()
percent = 100 * data[feature].value_counts(normalize=True)

df = pd.DataFrame({'jumlah sampel': count, 'persentase': percent.round(1)})
print(df)

ax = count.plot(kind='bar', title=feature)

for p in ax.patches:
    ax.annotate(f'{p.get_height()}',
                (p.get_x() + p.get_width() / 2., p.get_height()),
                ha='center', va='bottom', # Changed 'center bottom' to 'bottom'
                fontsize=10, color='black',
                xytext=(0, 5), textcoords='offset points')

plt.show()

"""Terlihat bahwa jumlah sampel yang tidak merokok adalah sebanyak 501 orang, sedangkan yang merokok sebanyak 499 orang.

### Numerical Feature
"""

data[numerical_features].hist(bins=50, figsize=(20, 15))
plt.suptitle('Histogram Fitur Numerik', fontsize=16)
plt.show()

"""Histogram fitur numerik ini menggambarkan distribusi berbagai fitur kesehatan dan kebiasaan pada sampel data yang cukup beragam. Usia responden tersebar secara normal dengan sebagian besar berada pada rentang 20 hingga 60 tahun, menunjukkan keragaman kelompok umur. Indeks massa tubuh (BMI) juga mengikuti pola distribusi normal dengan nilai mayoritas di kisaran 18 hingga 35, mencerminkan variasi status berat badan dari yang kurus hingga kelebihan berat badan. Frekuensi olahraga merupakan fitur diskrit dengan distribusi yang relatif merata dari nol hingga enam hari per minggu, menunjukkan perbedaan kebiasaan aktivitas fisik di antara responden. Kualitas diet dan jam tidur memiliki pola distribusi normal dengan puncak pada kualitas diet sedang hingga baik serta jam tidur ideal antara enam sampai delapan jam. Konsumsi alkohol menunjukkan variasi dengan mayoritas pada tingkat konsumsi sedang, meskipun data ini mungkin mengalami transformasi nilai. Sementara itu, skor kesehatan menunjukkan pola distribusi yang tidak normal, dengan banyak responden mengisi nilai maksimal, yang dapat menunjukkan banyaknya individu dengan kondisi kesehatan sangat baik atau adanya batasan skor. Secara keseluruhan, data ini memberikan gambaran populasi yang sehat dengan variasi wajar dalam kebiasaan dan kondisi fisik, namun perlu perhatian pada distribusi skor kesehatan yang terpusat pada nilai maksimum."""

for feature in categorical_features:
    counts = data[feature].value_counts()
    labels = counts.index.tolist()
    sizes = counts.values.tolist()

    plt.figure(figsize=(7,7))
    plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=140)
    plt.title(f'Proporsi Distribusi {feature}')
    plt.axis('equal')
    plt.show()

"""Proporsi fitur smoking status, terlihat bahwa banyaknya orang yang merokok sebanyak 49,9% dan yang tidak merokok sebanyak 50,1%.

## Exploratory Data Analysis - Multivariate Analysis

### Categorical Feature
"""

import seaborn as sns
import matplotlib.pyplot as plt

cat_features = ['Smoking_Status']

for col in cat_features:
    g = sns.catplot(
        x=col,
        y="Health_Score",
        kind="bar",
        dodge=False,
        height=4,
        aspect=3,
        data=data,
        palette="Set3"
    )

    plt.title(f"Average Health_Score relative to {col}")

    for p in g.ax.patches:
        height = p.get_height()
        g.ax.text(
            p.get_x() + p.get_width() / 2.,
            height + (height * 0.05),
            f'{height:.2f}',
            ha="center"
        )
    plt.show()

"""Barchart menunjukkan bahwa rata-rata skor kesehatan pada kelompok non-perokok (Smoking_Status = 0) sebesar 86,96, sedikit lebih tinggi dibandingkan dengan kelompok perokok (Smoking_Status = 1) yang memiliki rata-rata skor kesehatan 83,99. Perbedaan ini mengindikasikan bahwa status merokok berpengaruh negatif terhadap kesehatan, di mana perokok cenderung memiliki kondisi kesehatan yang lebih rendah.

### Numerical Feature
"""

sns.pairplot(data[numerical_features], diag_kind='kde')
plt.suptitle('Pairplot Fitur Numerik', y=1.02)
plt.show()

"""Pairplot ini memperlihatkan hubungan antar fitur numerik dalam data kesehatan. Skor kesehatan (Health Score) memiliki korelasi positif dengan kualitas diet (Diet Quality), frekuensi olahraga (Exercise Frequency), dan jam tidur (Sleep Hours), yang menunjukkan bahwa gaya hidup sehat berkontribusi meningkatkan kesehatan. Sebaliknya, usia (Age) dan indeks massa tubuh (BMI) menunjukkan korelasi negatif dengan skor kesehatan, yang berarti peningkatan usia dan BMI berpotensi menurunkan kondisi kesehatan. Distribusi frekuensi olahraga berupa hitungan jumlah olahraga dalam satu minggu dan tersebar merata. Secara keseluruhan, pola ini menegaskan pentingnya gaya hidup sehat dalam menunjang skor kesehatan responden."""

plt.figure(figsize=(10, 8))
correlation_matrix = data[numerical_features].corr().round(2)

# Untuk menge-print nilai di dalam kotak, gunakan parameter anot=True
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

"""Matriks korelasi pada gambar menunjukkan hubungan antar fitur numerik dalam data kesehatan. Hasil analisis memperlihatkan bahwa kualitas diet memiliki korelasi positif paling kuat dengan skor kesehatan (0,68), menandakan bahwa pola makan yang baik sangat berkontribusi terhadap peningkatan kesehatan. Selain itu, jam tidur (0,27) dan frekuensi olahraga (0,25) juga menunjukkan korelasi positif sedang dengan skor kesehatan, yang mengindikasikan pentingnya tidur cukup dan aktivitas fisik rutin dalam menunjang kesehatan. Sebaliknya, indeks massa tubuh (BMI) memiliki korelasi negatif yang cukup signifikan (-0,42) dengan skor kesehatan, serta usia juga menunjukkan korelasi negatif lemah (-0,19), menunjukkan bahwa peningkatan berat badan dan bertambahnya usia berpotensi menurunkan kondisi kesehatan. Konsumsi alkohol menunjukkan korelasi negatif ringan (-0,14), sementara korelasi antar fitur lain relatif kecil, menandakan fitur-fitur tersebut relatif independen satu sama lain dalam kaitannya dengan skor kesehatan.

Berdasarkan analisis korelasi dan visualisasi multivariat, fitur-fitur gaya hidup seperti kualitas diet, frekuensi olahraga, dan jam tidur menunjukkan pengaruh positif terhadap skor kesehatan, sedangkan BMI dan usia memberikan pengaruh negatif yang signifikan.

# Data Preparation

## Encoding Data Categorical

Karena dataset yang digunakan yang harusnya kategorik sudah dalam tipe numerik maka tidak perlu dilakukan encoding.

## Train Test Split

Dataset dibagi menjadi 80:20, yaitu 80% untuk data training dan 20% untuk data testing. Pembagian tersebut merupakan pembagian yang umum digunakan untuk memberikan keseimbangan antara jumlah data yang cukup untuk melatih model dan jumlah data yang cukup untuk menguji performa model. Namun, tidak ada aturan khusus dalam pembagian data ini, bergantung pada jenis data yang digunakan dan juga sesuai kebutuhan analisis.
"""

from sklearn.model_selection import train_test_split

X = data.drop(["Health_Score"],axis =1)
y = data["Health_Score"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)

print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

"""## Standarisasi

Standarisasi fitur numerik. Standarisasi merupakan proses mengubah skala data agar memiliki rata-rata (mean) = 0 dan simpangan baku (standar deviasi) = 1. Tujuannya adalah membantu model bekerja lebih optimal.
"""

from sklearn.preprocessing import StandardScaler

numerical_features = ['Age', 'BMI', 'Exercise_Frequency', 'Diet_Quality', 'Sleep_Hours','Alcohol_Consumption']
scaler = StandardScaler()
scaler.fit(X_train[numerical_features])
X_train[numerical_features] = scaler.transform(X_train.loc[:, numerical_features])
X_train[numerical_features].head()

X_train[numerical_features].describe().round(4)

"""# Model Development

Pada tahap ini, kita akan mengembangkan model machine learning dengan tiga algoritma. Kemudian, kita akan mengevaluasi performa masing-masing algoritma dan menentukan algoritma mana yang memberikan hasil prediksi terbaik. Ketiga algoritma yang akan kita gunakan, antara lain:
- SVR
- Random Forest
- Boosting Algorithm
"""

metrics = ['MAE', 'MSE', 'RMSE', 'R2']
datasets = ['train', 'test']
models = ['SVR', 'RandomForest', 'XGBoost']

index = pd.MultiIndex.from_product([metrics, datasets], names=['Metric', 'Dataset'])

models = pd.DataFrame(index=index, columns=models)

"""## SVR"""

from sklearn.svm import SVR
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import make_scorer, mean_squared_error

svr = SVR()
mse_scorer = make_scorer(mean_squared_error, greater_is_better=False)
param_grid_svr = {
    'kernel': ['rbf', 'linear'],
    'C': [0.1, 1, 10, 100],
    'gamma': ['scale', 'auto'],
    'epsilon': [0.01, 0.1, 0.2]
}

grid_search_svr = GridSearchCV(
    estimator=svr,
    param_grid=param_grid_svr,
    scoring=mse_scorer,
    cv=3,
    n_jobs=-1,
    verbose=1
)

grid_search_svr.fit(X_train, y_train)

best_svr = grid_search_svr.best_estimator_
print("Best parameters:", grid_search_svr.best_params_)
print("Best CV MSE:", -grid_search_svr.best_score_)

y_train_pred = best_svr.predict(X_train)
y_test_pred = best_svr.predict(X_test)

models.loc[('MAE', 'train'), 'SVR'] = mean_absolute_error(y_train, y_train_pred)
models.loc[('MSE', 'train'), 'SVR'] = mean_squared_error(y_train, y_train_pred)
models.loc[('RMSE', 'train'), 'SVR'] = np.sqrt(mean_squared_error(y_train, y_train_pred))
models.loc[('R2', 'train'), 'SVR'] = r2_score(y_train, y_train_pred)

models.loc[('MAE', 'test'), 'SVR'] = mean_absolute_error(y_test, y_test_pred)
models.loc[('MSE', 'test'), 'SVR'] = mean_squared_error(y_test, y_test_pred)
models.loc[('RMSE', 'test'), 'SVR'] = np.sqrt(mean_squared_error(y_test, y_test_pred))
models.loc[('R2', 'test'), 'SVR'] = r2_score(y_test, y_test_pred)

"""Best parameters dari pemodelan menggunakan SVR, yaitu {'C': 10, 'epsilon': 0.2, 'gamma': 'auto', 'kernel': 'rbf'} dengan Best CV MSE sebesar 26,23

## Random Forest
"""

from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestRegressor

rf = RandomForestRegressor(random_state=55, n_jobs=-1)

param_grid_rf = {
    'n_estimators': [50, 100],
    'max_depth': [10, 16],
    'min_samples_split': [2, 5],
    'min_samples_leaf': [1, 2]
}

grid_search_rf = GridSearchCV(
    estimator=rf,
    param_grid=param_grid_rf,
    scoring='neg_mean_squared_error',
    cv=3,
    n_jobs=-1,
    verbose=1
)

grid_search_rf.fit(X_train, y_train)

best_rf = grid_search_rf.best_estimator_
print("Best parameters Random Forest:", grid_search_rf.best_params_)
print("Best CV MSE Random Forest:", -grid_search_rf.best_score_)

y_train_pred = best_rf.predict(X_train)
y_test_pred = best_rf.predict(X_test)

models.loc[('MAE', 'train'), 'RandomForest'] = mean_absolute_error(y_train, y_train_pred)
models.loc[('MSE', 'train'), 'RandomForest'] = mean_squared_error(y_train, y_train_pred)
models.loc[('RMSE', 'train'), 'RandomForest'] = np.sqrt(mean_squared_error(y_train, y_train_pred))
models.loc[('R2', 'train'), 'RandomForest'] = r2_score(y_train, y_train_pred)

models.loc[('MAE', 'test'), 'RandomForest'] = mean_absolute_error(y_test, y_test_pred)
models.loc[('MSE', 'test'), 'RandomForest'] = mean_squared_error(y_test, y_test_pred)
models.loc[('RMSE', 'test'), 'RandomForest'] = np.sqrt(mean_squared_error(y_test, y_test_pred))
models.loc[('R2', 'test'), 'RandomForest'] = r2_score(y_test, y_test_pred)

"""Best parameters Random Forest: {'max_depth': 16, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100} dengan Best CV MSE sebesar 40,76.

## XGBoost
"""

from sklearn.model_selection import GridSearchCV
from xgboost import XGBRegressor

xgb = XGBRegressor(random_state=55, n_jobs=-1)

param_grid = {
    'n_estimators': [50, 100],
    'learning_rate': [0.05, 0.1],
    'max_depth': [3, 5]
}

grid_search_xgb = GridSearchCV(
    estimator=xgb,
    param_grid=param_grid,
    scoring='neg_mean_squared_error',
    cv=3,
    n_jobs=-1,
    verbose=1
)

grid_search_xgb.fit(X_train, y_train)

best_xgb = grid_search_xgb.best_estimator_
print("Best parameters XGBoost:", grid_search_xgb.best_params_)
print("Best CV MSE XGBoost:", -grid_search_xgb.best_score_)

y_train_pred = best_xgb.predict(X_train)
y_test_pred = best_xgb.predict(X_test)

models.loc[('MAE', 'train'), 'XGBoost'] = mean_absolute_error(y_train, y_train_pred)
models.loc[('MSE', 'train'), 'XGBoost'] = mean_squared_error(y_train, y_train_pred)
models.loc[('RMSE', 'train'), 'XGBoost'] = np.sqrt(mean_squared_error(y_train, y_train_pred))
models.loc[('R2', 'train'), 'XGBoost'] = r2_score(y_train, y_train_pred)

models.loc[('MAE', 'test'), 'XGBoost'] = mean_absolute_error(y_test, y_test_pred)
models.loc[('MSE', 'test'), 'XGBoost'] = mean_squared_error(y_test, y_test_pred)
models.loc[('RMSE', 'test'), 'XGBoost'] = np.sqrt(mean_squared_error(y_test, y_test_pred))
models.loc[('R2', 'test'), 'XGBoost'] = r2_score(y_test, y_test_pred)

"""Best parameter XGBoost: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}) dengan Best CV MSE sebesar 31,11

# Model Evaluation

Evaluasi model yang sudah dibangun menggunakan beberapa metrik, yaitu MAE, MSE, RMSE, dan R².
"""

# Lakukan scaling terhadap fitur numerik pada X_test sehingga memiliki rata-rata=0 dan varians=1
X_test.loc[:, numerical_features] = X_test.loc[:, numerical_features].astype(float)
X_test.loc[:, numerical_features] = scaler.transform(X_test.loc[:, numerical_features])

model_dict = {'SVR': best_svr, 'RandomForest': best_rf, 'XGBoost': best_xgb}

for name, model in model_dict.items():
    y_train_pred = model.predict(X_train)
    y_test_pred = model.predict(X_test)

    models.loc[('MAE', 'train'), name] = mean_absolute_error(y_train, y_train_pred)
    models.loc[('MSE', 'train'), name] = mean_squared_error(y_train, y_train_pred)
    models.loc[('RMSE', 'train'), name] = np.sqrt(mean_squared_error(y_train, y_train_pred))
    models.loc[('R2', 'train'), name] = r2_score(y_train, y_train_pred)

    models.loc[('MAE', 'test'), name] = mean_absolute_error(y_test, y_test_pred)
    models.loc[('MSE', 'test'), name] = mean_squared_error(y_test, y_test_pred)
    models.loc[('RMSE', 'test'), name] = np.sqrt(mean_squared_error(y_test, y_test_pred))
    models.loc[('R2', 'test'), name] = r2_score(y_test, y_test_pred)

print(models)

"""- Nilai MAE lebih kecil menunjukkan prediksi lebih akurat secara rata-rata. Pada data test, SVR menghasilkan MAE 3.65 yang lebih baik dibanding RandomForest (4.03) dan XGBoost (3.99). Ini berarti prediksi SVR lebih dekat secara rata-rata ke nilai sebenarnya.
- MSE memberi penalti lebih berat terhadap kesalahan yang besar. Nilai MSE test SVR (26.83) lebih rendah daripada RandomForest (31.59) dan XGBoost (28.89), menunjukkan model SVR memiliki kesalahan kuadrat yang lebih kecil. Namun, perbedaan tidak terlalu besar.
- RMSE test SVR (5.18) sedikit lebih rendah dibanding RandomForest (5.62) dan XGBoost (5.37), mengonfirmasi bahwa model SVR secara umum memiliki kesalahan prediksi yang lebih kecil.
- Nilai R² test SVR (0.86) tertinggi dibandingkan RandomForest (0.84) dan XGBoost (0.85), menandakan SVR mampu menjelaskan variansi health score paling baik pada data test. Nilai R2 di atas 0.8 menunjukkan model yang cukup baik dalam memprediksi target.
"""

datasets = ['train', 'test']
metrics = ['MAE', 'MSE', 'RMSE', 'R2']

for dataset in datasets:
    for metric in metrics:
        plt.figure(figsize=(8, 4))
        data_to_plot = models.loc[(metric, dataset)]
        data_to_plot.sort_values(ascending=False).plot(kind='barh')
        plt.title(f'{metric} pada {dataset} dataset')
        plt.xlabel(metric)
        plt.grid(True)
        plt.show()

prediksi = X_test.iloc[:5].copy()
pred_dict = {'y_true':y_test[:5]}
for name, model in model_dict.items():
    pred_dict['prediksi_'+name] = model.predict(prediksi).round(1)

pd.DataFrame(pred_dict)

"""Contoh prediksi untuk lima data."""